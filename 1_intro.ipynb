{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307eef94",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9f587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f6b3c",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b16ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd58ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85444e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec96b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сreate data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822748d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094e3ce",
   "metadata": {},
   "source": [
    "## Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b5a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f82d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de69dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69841be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing the model parameters  \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1e028",
   "metadata": {},
   "source": [
    "## Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db4b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1336c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bbaf4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306765  [    0/60000]\n",
      "loss: 2.289407  [ 6400/60000]\n",
      "loss: 2.272102  [12800/60000]\n",
      "loss: 2.268817  [19200/60000]\n",
      "loss: 2.249378  [25600/60000]\n",
      "loss: 2.204058  [32000/60000]\n",
      "loss: 2.235938  [38400/60000]\n",
      "loss: 2.188392  [44800/60000]\n",
      "loss: 2.188013  [51200/60000]\n",
      "loss: 2.165030  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 2.153092 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.163739  [    0/60000]\n",
      "loss: 2.159197  [ 6400/60000]\n",
      "loss: 2.100040  [12800/60000]\n",
      "loss: 2.123592  [19200/60000]\n",
      "loss: 2.072480  [25600/60000]\n",
      "loss: 1.990853  [32000/60000]\n",
      "loss: 2.046321  [38400/60000]\n",
      "loss: 1.955712  [44800/60000]\n",
      "loss: 1.964141  [51200/60000]\n",
      "loss: 1.902107  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 1.892273 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.922015  [    0/60000]\n",
      "loss: 1.898548  [ 6400/60000]\n",
      "loss: 1.776408  [12800/60000]\n",
      "loss: 1.822877  [19200/60000]\n",
      "loss: 1.713807  [25600/60000]\n",
      "loss: 1.644463  [32000/60000]\n",
      "loss: 1.688609  [38400/60000]\n",
      "loss: 1.578036  [44800/60000]\n",
      "loss: 1.602716  [51200/60000]\n",
      "loss: 1.501908  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.512762 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.580597  [    0/60000]\n",
      "loss: 1.548873  [ 6400/60000]\n",
      "loss: 1.390120  [12800/60000]\n",
      "loss: 1.462300  [19200/60000]\n",
      "loss: 1.342901  [25600/60000]\n",
      "loss: 1.325665  [32000/60000]\n",
      "loss: 1.359387  [38400/60000]\n",
      "loss: 1.273479  [44800/60000]\n",
      "loss: 1.309660  [51200/60000]\n",
      "loss: 1.215431  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.236876 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.316131  [    0/60000]\n",
      "loss: 1.303226  [ 6400/60000]\n",
      "loss: 1.130690  [12800/60000]\n",
      "loss: 1.233299  [19200/60000]\n",
      "loss: 1.108938  [25600/60000]\n",
      "loss: 1.122053  [32000/60000]\n",
      "loss: 1.166810  [38400/60000]\n",
      "loss: 1.091117  [44800/60000]\n",
      "loss: 1.132274  [51200/60000]\n",
      "loss: 1.058038  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.073423 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc562d",
   "metadata": {},
   "source": [
    "## Saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae86ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6dfe1",
   "metadata": {},
   "source": [
    "## Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938fa246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"models/model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c3454",
   "metadata": {},
   "source": [
    "## Testing model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27196214",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80308b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f02f0",
   "metadata": {},
   "source": [
    "# Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f02c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1c888",
   "metadata": {},
   "source": [
    "## Initializing a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcc391e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "417d0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cdb43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4368, 0.3252],\n",
      "        [0.7752, 0.3434]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00ca6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7900, 0.7319, 0.1339],\n",
      "        [0.3666, 0.3437, 0.2959]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# with random or constant values\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0abbba",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79e75fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbf640",
   "metadata": {},
   "source": [
    "## Operations on Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0759e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e60b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# standard numpy-like indexing and slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7701fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e583d08",
   "metadata": {},
   "source": [
    "## Arithmetic operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ae0d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a74bbf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "572569c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Single-element tensors \n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dda33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place operations \n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae91dae",
   "metadata": {},
   "source": [
    "## Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd10aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20408fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311a813",
   "metadata": {},
   "source": [
    "## NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43aca7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f35b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012bf8c",
   "metadata": {},
   "source": [
    "# Dataset and DataLoaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be74c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2f2ec",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9a55b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d9f3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10883988",
   "metadata": {},
   "source": [
    "## Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f4899db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0555e938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c1e01",
   "metadata": {},
   "source": [
    "## Creating a Custom Dataset for your files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43b26f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14c85273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786228e9",
   "metadata": {},
   "source": [
    "## Preparing your data for training with DataLoaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7748d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19b9972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b5596",
   "metadata": {},
   "source": [
    "## Iterate through the DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f3eb448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0323b67",
   "metadata": {},
   "source": [
    "# Transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d92c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b0c1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117054b",
   "metadata": {},
   "source": [
    "## Lambda Transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa2c3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad074b7e",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dec1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22891623",
   "metadata": {},
   "source": [
    "## Get Device for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cf1401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cea3ba",
   "metadata": {},
   "source": [
    "## Define the Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05b68ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "655a7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d14e7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b11561",
   "metadata": {},
   "source": [
    "## Model Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf1aa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "418499d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e63fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# linear\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b9e1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.1687, -0.1956,  0.2802, -0.4392,  0.1997, -0.4515,  0.4614, -0.5147,\n",
      "          0.0624,  0.2011,  0.0072, -0.0355,  0.3352,  0.7986,  0.3968, -0.3198,\n",
      "          1.1818,  0.1995,  0.1524,  0.1650],\n",
      "        [ 0.0535, -0.2998,  0.2412, -0.8002, -0.1181, -0.4188,  0.6252, -0.7284,\n",
      "          0.2015,  0.2831,  0.2799, -0.0638,  0.4838,  0.1765,  0.3788, -0.2167,\n",
      "          1.0462, -0.0527,  0.4605,  0.2196],\n",
      "        [-0.1351, -0.1260,  0.5560, -0.4956,  0.0887, -0.4958,  0.3854, -0.3179,\n",
      "          0.0087,  0.2054,  0.2911, -0.1528,  0.0230,  0.8884,  0.2549, -0.0630,\n",
      "          1.0017,  0.0981,  0.6182,  0.3117]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.1687, 0.0000, 0.2802, 0.0000, 0.1997, 0.0000, 0.4614, 0.0000, 0.0624,\n",
      "         0.2011, 0.0072, 0.0000, 0.3352, 0.7986, 0.3968, 0.0000, 1.1818, 0.1995,\n",
      "         0.1524, 0.1650],\n",
      "        [0.0535, 0.0000, 0.2412, 0.0000, 0.0000, 0.0000, 0.6252, 0.0000, 0.2015,\n",
      "         0.2831, 0.2799, 0.0000, 0.4838, 0.1765, 0.3788, 0.0000, 1.0462, 0.0000,\n",
      "         0.4605, 0.2196],\n",
      "        [0.0000, 0.0000, 0.5560, 0.0000, 0.0887, 0.0000, 0.3854, 0.0000, 0.0087,\n",
      "         0.2054, 0.2911, 0.0000, 0.0230, 0.8884, 0.2549, 0.0000, 1.0017, 0.0981,\n",
      "         0.6182, 0.3117]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f82cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf09a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d661b",
   "metadata": {},
   "source": [
    "## Model Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b96fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0102,  0.0280, -0.0073,  ...,  0.0136, -0.0291, -0.0345],\n",
      "        [-0.0287, -0.0008,  0.0148,  ..., -0.0106,  0.0338, -0.0078]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0325, -0.0067], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0018,  0.0107,  0.0229,  ..., -0.0157,  0.0371,  0.0086],\n",
      "        [ 0.0069,  0.0390, -0.0032,  ...,  0.0242,  0.0435,  0.0048]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0431, 0.0372], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0097, -0.0065, -0.0359,  ...,  0.0100,  0.0260,  0.0013],\n",
      "        [-0.0231, -0.0324,  0.0107,  ...,  0.0091,  0.0090, -0.0104]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0212, 0.0286], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683435fe",
   "metadata": {},
   "source": [
    "# Autograd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93f81de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e22a48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea32dd",
   "metadata": {},
   "source": [
    "## Tensors, Functions and Computational graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a93493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x0000012BD0CB6CA0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x0000012BD0CB64C0>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9ffb1",
   "metadata": {},
   "source": [
    "## Computing Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12e267ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2490, 0.3204, 0.0620],\n",
      "        [0.2490, 0.3204, 0.0620],\n",
      "        [0.2490, 0.3204, 0.0620],\n",
      "        [0.2490, 0.3204, 0.0620],\n",
      "        [0.2490, 0.3204, 0.0620]])\n",
      "tensor([0.2490, 0.3204, 0.0620])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49626098",
   "metadata": {},
   "source": [
    "## Disabling Gradient Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "198a33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17bfe3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d2142be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13557e6",
   "metadata": {},
   "source": [
    "## Optional Reading: Tensor Gradients and Jacobian Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df6490dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039d031",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e263293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4cfd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a07fc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b67b45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69eeb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a77cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c859b",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44508154",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b98225",
   "metadata": {},
   "source": [
    "## Optimization Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5eeebf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "218bf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06748a3",
   "metadata": {},
   "source": [
    "## Full Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4bf47a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd180f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16608405",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c311a59d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296452  [    0/60000]\n",
      "loss: 2.285799  [ 6400/60000]\n",
      "loss: 2.275350  [12800/60000]\n",
      "loss: 2.275268  [19200/60000]\n",
      "loss: 2.244518  [25600/60000]\n",
      "loss: 2.226461  [32000/60000]\n",
      "loss: 2.231143  [38400/60000]\n",
      "loss: 2.205551  [44800/60000]\n",
      "loss: 2.187470  [51200/60000]\n",
      "loss: 2.179275  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 2.164763 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165071  [    0/60000]\n",
      "loss: 2.162965  [ 6400/60000]\n",
      "loss: 2.112206  [12800/60000]\n",
      "loss: 2.132215  [19200/60000]\n",
      "loss: 2.080093  [25600/60000]\n",
      "loss: 2.026479  [32000/60000]\n",
      "loss: 2.053614  [38400/60000]\n",
      "loss: 1.987560  [44800/60000]\n",
      "loss: 1.972727  [51200/60000]\n",
      "loss: 1.923717  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.913128 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.935386  [    0/60000]\n",
      "loss: 1.916530  [ 6400/60000]\n",
      "loss: 1.801659  [12800/60000]\n",
      "loss: 1.845453  [19200/60000]\n",
      "loss: 1.729627  [25600/60000]\n",
      "loss: 1.682860  [32000/60000]\n",
      "loss: 1.709358  [38400/60000]\n",
      "loss: 1.614320  [44800/60000]\n",
      "loss: 1.620603  [51200/60000]\n",
      "loss: 1.528134  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.536406 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.598717  [    0/60000]\n",
      "loss: 1.566999  [ 6400/60000]\n",
      "loss: 1.413571  [12800/60000]\n",
      "loss: 1.490128  [19200/60000]\n",
      "loss: 1.357646  [25600/60000]\n",
      "loss: 1.356816  [32000/60000]\n",
      "loss: 1.380733  [38400/60000]\n",
      "loss: 1.302956  [44800/60000]\n",
      "loss: 1.327391  [51200/60000]\n",
      "loss: 1.236703  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.256842 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.337322  [    0/60000]\n",
      "loss: 1.319173  [ 6400/60000]\n",
      "loss: 1.148417  [12800/60000]\n",
      "loss: 1.259575  [19200/60000]\n",
      "loss: 1.128088  [25600/60000]\n",
      "loss: 1.151934  [32000/60000]\n",
      "loss: 1.185347  [38400/60000]\n",
      "loss: 1.117919  [44800/60000]\n",
      "loss: 1.148918  [51200/60000]\n",
      "loss: 1.075178  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.090196 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.167254  [    0/60000]\n",
      "loss: 1.168495  [ 6400/60000]\n",
      "loss: 0.978679  [12800/60000]\n",
      "loss: 1.120551  [19200/60000]\n",
      "loss: 0.989894  [25600/60000]\n",
      "loss: 1.017727  [32000/60000]\n",
      "loss: 1.067330  [38400/60000]\n",
      "loss: 1.002333  [44800/60000]\n",
      "loss: 1.035199  [51200/60000]\n",
      "loss: 0.976755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.984429 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.050258  [    0/60000]\n",
      "loss: 1.071900  [ 6400/60000]\n",
      "loss: 0.863190  [12800/60000]\n",
      "loss: 1.029262  [19200/60000]\n",
      "loss: 0.903133  [25600/60000]\n",
      "loss: 0.923768  [32000/60000]\n",
      "loss: 0.990363  [38400/60000]\n",
      "loss: 0.926742  [44800/60000]\n",
      "loss: 0.957563  [51200/60000]\n",
      "loss: 0.911017  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.912413 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.963792  [    0/60000]\n",
      "loss: 1.004501  [ 6400/60000]\n",
      "loss: 0.779991  [12800/60000]\n",
      "loss: 0.964540  [19200/60000]\n",
      "loss: 0.844965  [25600/60000]\n",
      "loss: 0.854679  [32000/60000]\n",
      "loss: 0.935517  [38400/60000]\n",
      "loss: 0.874728  [44800/60000]\n",
      "loss: 0.901918  [51200/60000]\n",
      "loss: 0.863131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.860294 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.896524  [    0/60000]\n",
      "loss: 0.953635  [ 6400/60000]\n",
      "loss: 0.717605  [12800/60000]\n",
      "loss: 0.916253  [19200/60000]\n",
      "loss: 0.803448  [25600/60000]\n",
      "loss: 0.802588  [32000/60000]\n",
      "loss: 0.893435  [38400/60000]\n",
      "loss: 0.837769  [44800/60000]\n",
      "loss: 0.860590  [51200/60000]\n",
      "loss: 0.826251  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.820705 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.842415  [    0/60000]\n",
      "loss: 0.912714  [ 6400/60000]\n",
      "loss: 0.669207  [12800/60000]\n",
      "loss: 0.878597  [19200/60000]\n",
      "loss: 0.772028  [25600/60000]\n",
      "loss: 0.762426  [32000/60000]\n",
      "loss: 0.859028  [38400/60000]\n",
      "loss: 0.810125  [44800/60000]\n",
      "loss: 0.828726  [51200/60000]\n",
      "loss: 0.796281  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.789174 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3cab2",
   "metadata": {},
   "source": [
    "# Save and Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc4ec137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91220a0e",
   "metadata": {},
   "source": [
    "## Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df77653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'models/model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "76c74440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('models/model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2af985",
   "metadata": {},
   "source": [
    "## Models with Shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2bc27469",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2be46c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18f60e",
   "metadata": {},
   "source": [
    "## Exporting Model to ONNX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "45da5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aleks\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.zeros((1,3,224,224))\n",
    "onnx.export(model, input_image, 'models/model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
